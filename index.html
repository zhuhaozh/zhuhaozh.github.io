<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Hao Zhu</title>
  
  <meta name="author" content="Hao Zhu">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Hao Zhu ("朱昊" in Chinese)</name>
              </p>
              <p>Hao Zhu is currently researcher at <a href="https://www.sensetime.com/en">SenseTime</a>, where he works on generative models and neural rendering.
              </p>
              <p>
                He received his master degree from <a href="https://www.ahu.edu.cn/">Anhui University</a> and is also a joint master student at <a href="http://cripac.ia.ac.cn/en/EN/volumn/home.shtml">CRIPAC</a>, <a href="http://english.ia.cas.cn/">CASIA</a>, supervised by <a href="https://rhe-web.github.io/">Prof. Ran He</a> and <a href="https://scholar.google.com.hk/citations?user=vcMHRWEAAAAJ&hl">Prof. Aihua Zheng</a>.
              </p>
              <p>Please feel free to contact me through email if you have any questions. </p>
              <p style="text-align:center">
                <a href="mailto:haozhu96@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=sntA9FgAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/zhuhaozh/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/zh.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/zh.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <!-- News -->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>News</heading>
            <p>[Jul 2021] Join SenseTime as a fulltime researcher working on generative models and neural rendering. If you are interested in a research internship position, please contact us.</p>
            <p>[Oct 2020] One paper on face swapping was accepted to NeurIPS 2020. </p>
            <p>[Sep 2018] Start my graduate study and research at Anhui University and CRIPAC CASIA. </p>
        </td>
        </tr>
      </tbody></table>

       <!-- News -->

        
      <!-- publications -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in computer vision, machine learning, and image processing. Much of my research is about high-quality generative works. 
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
<!-- 
          <tr onmouseout="clipnerf_stop()" onmouseover="clipnerf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='clipnerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/dreamfield_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/aot_nips20.png' width="160">
              </div>
              <script type="text/javascript">
                function clipnerf_start() {
                  document.getElementById('clipnerf_image').style.opacity = "1";
                }

                function clipnerf_stop() {
                  document.getElementById('clipnerf_image').style.opacity = "0";
                }
                clipnerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ajayj.com/dreamfields">
                <papertitle>Zero-Shot Text-Guided Object Generation with Dream Fields</papertitle>
              </a>
              <br>
              <a href="https://www.ajayj.com/">Ajay Jain</a>,
              <a href="https://bmild.github.io/">Ben Mildenhall</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="https://people.eecs.berkeley.edu/~pabbeel/">Pieter Abbeel</a>,
              <a href="https://cs.stanford.edu/~poole/">Ben Poole</a>
              <br>
        <em>arXiv</em>, 2021
              <br>
              <a href="https://ajayj.com/dreamfields">project page</a>
        /
              <a href="https://arxiv.org/abs/2112.01455">arXiv</a>
        /
              <a href="https://www.youtube.com/watch?v=1Fke6w46tv4">video</a>
              <p></p>
              <p>Supervising the CLIP embeddings of NeRF renderings lets us to generate 3D objects from text prompts.</p>
            </td>
          </tr>  -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div>
                <img src='images/survey_ijac21.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="#">
                <papertitle>Deep audio-visual learning: A survey</papertitle>
              </a>
              <br>
              <strong>Hao Zhu</strong>, 
              <a href="#">Mandi Luo</a>,
              <a href="#">Rui Wang</a>,
              <a href="#">Aihua Zheng</a>, 
              <a href="#">Ran He</a>
              <br>
        <em>IJAC</em>, 2021
              <br>
              <a href="http://www.ijac.net/en/article/doi/10.1007/s11633-021-1293-0">PDF</a>
              <p></p>
              <p>we provide a comprehensive survey of recent audio-visual learning development. </p>
            </td>
          </tr> 

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div>
                <img src='images/aot_nips20.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="projects/AOT/">
                <papertitle>AOT: Appearance Optimal Transport Based Identity Swapping for Forgery Detection                </papertitle>
              </a>
              <br>
              <strong>Hao Zhu</strong> <sup>*</sup>, 
              <a href="#">Chaoyou Fu</a> <sup>*</sup>,
              <a href="https://http://qianyiwu.github.io/">Qianyi Wu</a>,
              <a href="https://wywu.github.io/">Wayne Wu</a>, 
              <a href="#">Chen Qian</a>,
              <a href="https://rhe-web.github.io/">Ran He</a>
              <br>
        <em>NeurIPS</em>, 2020
              <br>
              <a href="projects/AOT">project page</a>
        /
              <a href="https://github.com/zhuhaozh/AOT">Code & Dataset</a>
        /
              <a href="http://arxiv.org/abs/2011.02674">arXiv</a>
              <p></p>
              <p>A new identity swapping algorithm with large differences in appearance for forgery detection.</p>
            </td>
          </tr> 

          <!-- IJCAI'20 -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div>
                <img src='images/amie_ijcai20.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="#">
                <papertitle>Arbitrary Talking Face Generation via Attentional Audio-visual Coherence Learning</papertitle>
              </a>
              <br>
              <strong>Hao Zhu</strong>,
              <a href="#">Huaibo Huang</a>,
              <a href="#">Yi Li</a>,
              <a href="#">Aihua Zheng</a>,
              <a href="#">Ran He</a>
              <br>
        <em>IJCAI</em>, 2020
              <br>
              <!-- <a href="https://github.com/zhuhaozh/AOT">project page</a> -->
        <!-- / -->
              <a href="http://arxiv.org/abs/1812.06589">arXiv</a>
              <p></p>
              <p>A novel arbitrary talking face generation framework by discovering the audio-visual coherence via the proposed Asymmetric Mutual Information Estimator (AMIE).</p>
            </td>
          </tr> 

          <!-- ICPR'20 -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div>
                <img src='images/apvg_icpr20.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="#">
                <papertitle>Let’s Play Music: Audio-driven Performance Video Generation</papertitle>
              </a>
              <br>
              <strong>Hao Zhu</strong>,
              <a href="#">Yi Li</a>,
              <a href="#">Feixia Zhu</a>, 
              <a href="#">Aihua Zheng</a>,
              <a href="#">Ran He</a>
              <br>
        <em>ICPR</em>, 2020
              <br>
              <!-- <a href="https://github.com/zhuhaozh/AOT">project page</a>
        / -->
              <a href="http://arxiv.org/abs/2011.02631">arXiv</a>
              <p></p>
              <p>A multi-staged framework to achieve this new task to generate realistic and synchronized performance video from given music.</p>
            </td>
          </tr> 

          <!-- ICPR'20 -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div>
                <img src='images/talkingface_zfx.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="#">
                <papertitle>Talking Face Generation via Learning Semantic and Temporal Synchronous Landmarks</papertitle>
              </a>
              <a href="#">Aihua Zheng</a>,
              <a href="#">Feixia Zhu</a>, 
              <strong>Hao Zhu</strong>,
              <a href="#">Mandi Luo</a>,
              <a href="#">Ran He</a>
              <br>
        <em>ICPR</em>, 2020
              <br>
              <!-- <a href="https://github.com/zhuhaozh/AOT">project page</a>
        / -->
              <a href="https://ieeexplore.ieee.org/document/9412425">PDF</a>
              <p></p>
              <!-- <p>A multi-staged framework to achieve this new task to generate realistic and synchronized performance video from given music.</p> -->
            </td>
          </tr> 

        </tbody></table>

      <!-- last info -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Template credits: <a href="https://jonbarron.info">Jon Barron</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
