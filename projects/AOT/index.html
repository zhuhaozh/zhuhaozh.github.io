
<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>AOT</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    
    <script src="js/app.js"></script>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-12 text-center">
                <b>AOT</b>: Appearance Optimal Transport Based Identity Swapping </br> for Forgery Detection
            </br> 
                <small>
                    NeurIPS 2020
                </small>
            </h2>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <a href="https://www.zhuhaozh.xyz/">
                         Hao Zhu 
                        </a> <sup>1,2</sup>
                        <!-- </br>CRIPAC, CASIA & AHU -->
                    </li>
                    <li>
                        <a href="#">
                            Chaoyou Fu
                        </a><sup>2</sup>
                        <!-- </br>Google -->
                    </li>
                    <li>
                        <a href="https://qianyiwu.github.io/">
                          Qianyi Wu
                        </a><sup>3</sup>
                        <!-- </br>UC Berkeley -->
                    </li> 
                    <!-- <br> -->
                    <li>
                        <a href="https://wywu.github.io/">
                          Wayne Wu
                        </a><sup>3</sup>
                        <!-- </br>Google -->
                    </li>
                    <li>
                        <a href="https://scholar.google.com/citations?user=AerkT0YAAAAJ&hl=en">
                          Chen Qian
                        </a><sup>3</sup>
                        <!-- </br>Google -->
                    </li>
                    <li>
                        <a href="https://scholar.google.com/citations?user=ayrg9AUAAAAJ&hl=en">
                          Ran He
                        </a><sup>2</sup>
                        <!-- </br>Google -->
                    </li>
                </ul>
                <ul class="list-inline">
                    <li><sup>1</sup><a>Anhui University</a></li>
                    <li><sup>2</sup><a>NLPR & CRIPAC, CASIA</a></li>
                    <li><sup>3</sup><a>SenseTime Research</a></li>
                </ul>
            </div>
        </div>


        <div class="row">
                <div class="col-md-4 col-md-offset-4 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
                            <a href="https://arxiv.org/abs/2103.13415">
                            <image src="img/paper_image.jpg" height="60px">
                                <h4><strong>Paper</strong></h4>
                            </a>
                        </li>
                        <!-- <li>
                            <a href="https://youtu.be/EpH175PY1A0">
                            <image src="img/youtube_icon.png" height="60px">
                                <h4><strong>Video</strong></h4>
                            </a>
                        </li> -->
                        <li>
                            <a href="https://github.com/zhuhaozh/AOT">
                            <image src="img/github.png" height="60px">
                                <h4><strong>Code & Dataset</strong></h4>
                            </a>
                        </li>
                    </ul>
                </div>
        </div>



        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                    <image src="img/banner.gif" width="100%" class="img-responsive" alt="overview">
                <br>
                <p class="text-justify">
Recent studies have shown that the performance of forgery detection can be improved with diverse and challenging Deepfakes datasets. However, due to the lack of Deepfakes datasets with large variance in appearance, which can be hardly produced by recent identity swapping methods, the detection algorithm may fail in this situation. 
In this work, we provide a new identity swapping algorithm with large differences in appearance for face forgery detection. The appearance gaps mainly arise from the large discrepancies in illuminations and skin colors that widely exist in real-world scenarios. However, due to the difficulties of modeling the complex appearance mapping, it is challenging to transfer fine-grained appearances adaptively while preserving identity traits. 
This paper formulates appearance mapping as an optimal transport problem and proposes an Appearance Optimal Transport model (AOT) to formulate it in both latent and pixel space. Specifically, a relighting generator is designed to simulate the optimal transport plan. It is solved via minimizing the Wasserstein distance of the learned features in the latent space, enabling better performance and less computation than conventional optimization. To further refine the solution of the optimal transport plan, we develop a segmentation game to minimize the Wasserstein distance in the pixel space. A discriminator is introduced to distinguish the fake parts from a mix of real and fake image patches. Extensive experiments reveal that the superiority of our method when compared with state-of-the-art methods and the ability of our generated data to improve the performance of face forgery detection.


                </p>
            </div>
        </div>



        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Pipeline
                </h3>
                <p style="text-align:center;">
                    <image src="img/pipeline.png" class="img-responsive" alt="scales">
                </p>
            </div>
        </div>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>Manipulated Dataset
                </h3>
                <p class="text-justify">
                    The following datasets and the checkpoints of detectors can be downloaded from the <a href="https://pan.baidu.com/s/143Xuvea-ICcFuvgYfyY-Wg">BaiduYun</a> (code: dzgc).
                </p>

                <p class="text-justify">
                    We currently provide 100 manipulated videos of <a href="#">FF++</a> by refining the results of <a href="#">DeepFaceLab</a> and <a href="#">DeeperForensics-1.0</a>, respectively.
                    The more manipulated videos are coming soon.
                </p>
                <p style="text-align:center;">
                    <image src="img/datasets.png" class="img-responsive" alt="scales">
                </p>
            </div>
        </div>
            


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Face Forgery Detection

                </h3>
                <p class="text-justify">
                    Binary detection accuracy of two video classification baselines: I3D and TSN on the hidden set provided by DeeperForensics-1.0.
                </p>
                <ol>
                    <li>We trained the baselines on four manipulated datasets of FF++ produced by DeepFakes, Face2Face, FaceSwap, and NeuralTextures (Green bars).
                    </li>
                    <li>Then, we add 100 manipulated videos produced by our method to the training set. All detection accuracies are improved with the addition of our data. (Blue bars).
                    </li>
                 </ol>
                 
                <p style="text-align:center;">
                    <image src="img/detection_results.png" class="img-responsive" alt="scales">
                </p>
                <p class="text-justify">
                    In order to pass this information through the NeRF network, we fit a multivariate Gaussian to the conical frustum and use the integrated positional encoding described above to create the input feature vector to the network. 
                </p>
            </div>
        </div>
            

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Citation
                </h3>
                <div class="form-group col-md-10 col-md-offset-1">
                    <textarea id="bibtex" class="form-control" readonly>@article{zhu2020aot,
    title={AOT: Appearance Optimal Transport Based Identity Swapping for Forgery Detection},
    author={Zhu, Hao and Fu, Chaoyou and Wu, Qianyi and Wu, Wayne and Qian, Chen and He, Ran},
    journal={Advances in Neural Information Processing Systems},
    volume={33},
    year={2020}
}</textarea>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Acknowledgements
                </h3>
                <p class="text-justify">
                ANY RESOUCES PROVIDED HERE ARE NOT TO BE USED FOR MALICIOUS OR INAPPROPRIATE USE CASES.
                </p>
            </div>
        </div>
    </div>
</body>
</html>
