<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Hao Zhu's publications</title>
  
  <meta name="author" content="Hao Zhu">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">

        
      <!-- publications -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research Publications</heading> <a href="https://www.zhuhaozh.xyz">[back to home page]</a>

            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <h2>2022</h2>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div>
                <img src='images/celebvhq.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="#">
                <papertitle>CelebV-HQ: A Large-Scale Video Facial Attributes Dataset</papertitle>
              </a>
              <br>
              <strong>Hao Zhu</strong>*, 
              Wayne Wu<sup>✉</sup>*,
              Wentao Zhu,
              Liming Jiang,
              Siwei Tang,
              Li Zhang,
              Ziwei Liu, and
              Chen Change Loy
              <br>
        <em>ECCV</em>, 2022
              <br>
              <a href='http://celebv-hq.github.io/'>Project Page</a>
              <p></p>
              <p> A large-scale, high-quality, and diverse video dataset with rich facial attribute annotations. CelebV-HQ contains 35,666 video clips with the resolution of 512x512 at least. All clips are labeled manually with 83 facial attributes, covering appearance, action, and emotion.</p>
            </td>
          </tr> 
        </tbody></table>

        <table>
          <h2 >2021</h2>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div>
                <img src='images/survey_ijac21.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="#">
                <papertitle>Deep audio-visual learning: A survey</papertitle>
              </a>
              <br>
              <strong>Hao Zhu</strong>, 
              Mandi Luo,
              Rui Wang,
              Aihua Zheng, and
              Ran He
              <br>
        <em>IJAC</em>, 2021
              <br>
              <a href="http://www.ijac.net/en/article/doi/10.1007/s11633-021-1293-0">PDF</a>
              <p></p>
              <p>we provide a comprehensive survey of recent audio-visual learning development. </p>
            </td>
          </tr> 
        </tbody></table>
        
        <table>
          <h2>2020</h2>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div>
                <img src='images/aot_nips20.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="projects/AOT/">
                <papertitle>AOT: Appearance Optimal Transport Based Identity Swapping for Forgery Detection                </papertitle>
              </a>
              <br>
              <strong>Hao Zhu</strong>* 
              Chaoyou Fu*,
              Qianyi Wu,
              Wayne Wu, 
              Chen Qian, and
              Ran He
              <br>
        <em>NeurIPS</em>, 2020
              <br>
              <a href="projects/AOT">project page</a>
        /
              <a href="https://github.com/zhuhaozh/AOT">Code & Dataset</a>
        /
              <a href="http://arxiv.org/abs/2011.02674">arXiv</a>
              <p></p>
              <p>A new identity swapping algorithm with large differences in appearance for forgery detection.</p>
            </td>
          </tr> 

          <!-- IJCAI'20 -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div>
                <img src='images/amie_ijcai20.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="#">
                <papertitle>Arbitrary Talking Face Generation via Attentional Audio-visual Coherence Learning</papertitle>
              </a>
              <br>
              <strong>Hao Zhu</strong>,
              Huaibo Huang,
              Yi Li,
              Aihua Zheng, and
              Ran He
              <br>
        <em>IJCAI</em>, 2020
              <br>
              <!-- <a href="https://github.com/zhuhaozh/AOT">project page</a> -->
        <!-- / -->
              <a href="http://arxiv.org/abs/1812.06589">arXiv</a>
              <p></p>
              <p>A novel arbitrary talking face generation framework by discovering the audio-visual coherence via the proposed Asymmetric Mutual Information Estimator (AMIE).</p>
            </td>
          </tr> 

          <!-- ICPR'20 -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div>
                <img src='images/apvg_icpr20.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="#">
                <papertitle>Let’s Play Music: Audio-driven Performance Video Generation</papertitle>
              </a>
              <br>
              <strong>Hao Zhu</strong>,
              Yi Li,
              Feixia Zhu, 
              Aihua Zheng, and
              Ran He
              <br>
        <em>ICPR</em>, 2020
              <br>
              <!-- <a href="https://github.com/zhuhaozh/AOT">project page</a>
        / -->
              <a href="http://arxiv.org/abs/2011.02631">arXiv</a>
              <p></p>
              <p>A multi-staged framework to achieve this new task to generate realistic and synchronized performance video from given music.</p>
            </td>
          </tr> 

          <!-- ICPR'20 -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div>
                <img src='images/talkingface_zfx.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="#">
                <papertitle>Talking Face Generation via Learning Semantic and Temporal Synchronous Landmarks</papertitle>
              </a>
              Aihua Zheng,
              Feixia Zhu, 
              <strong>Hao Zhu</strong>,
              Mandi Luo, and
              Ran He
              <br>
        <em>ICPR</em>, 2020
              <br>
              <!-- <a href="https://github.com/zhuhaozh/AOT">project page</a>
        / -->
              <a href="https://ieeexplore.ieee.org/document/9412425">PDF</a>
              <p></p>
              <!-- <p>A multi-staged framework to achieve this new task to generate realistic and synchronized performance video from given music.</p> -->
            </td>
          </tr> 

        </tbody></table>



          <!-- Awards -->

      </td>
    </tr>
  </table>
</body>

</html>
